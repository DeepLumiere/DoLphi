{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-17T17:38:36.925227Z",
     "start_time": "2025-07-17T17:38:31.593479Z"
    }
   },
   "source": [
    "#Importing Packages\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing as pre\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T17:38:40.530889Z",
     "start_time": "2025-07-17T17:38:39.445319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Move to CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "59b1997730f08f4c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T17:38:43.291442Z",
     "start_time": "2025-07-17T17:38:41.606993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# #Importing data from UNSW_NB15\n",
    "# train_df = pd.read_csv('data/UNSW_NB15_training-set.csv')\n",
    "# test_df = pd.read_csv('data/UNSW_NB15_testing-set.csv')\n",
    "#https://www.kaggle.com/datasets/nikhil1e9/loan-default\n",
    "df = pd.read_csv('data/creditcard.csv')\n",
    "\n",
    "df.info()"
   ],
   "id": "3a8cdff9faac9e5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T17:31:37.262455Z",
     "start_time": "2025-07-17T17:31:37.219835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "object_cols = ['type']\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Apply Label Encoding to each object column\n",
    "for col in object_cols:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "train_df, test_df = tts(df)\n"
   ],
   "id": "e4e915c9a4184925",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T17:31:37.787801Z",
     "start_time": "2025-07-17T17:31:37.760076Z"
    }
   },
   "cell_type": "code",
   "source": "train_df.info()",
   "id": "70b49f8f7d6cd472",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 76209 entries, 86152 to 78232\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   step            76209 non-null  int64  \n",
      " 1   type            76209 non-null  int64  \n",
      " 2   amount          76209 non-null  float64\n",
      " 3   nameOrig        76209 non-null  object \n",
      " 4   oldbalanceOrg   76209 non-null  float64\n",
      " 5   newbalanceOrig  76209 non-null  float64\n",
      " 6   nameDest        76209 non-null  object \n",
      " 7   oldbalanceDest  76209 non-null  float64\n",
      " 8   newbalanceDest  76209 non-null  float64\n",
      " 9   isFraud         76209 non-null  int64  \n",
      " 10  isFlaggedFraud  76209 non-null  int64  \n",
      "dtypes: float64(5), int64(4), object(2)\n",
      "memory usage: 7.0+ MB\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T17:31:38.485631Z",
     "start_time": "2025-07-17T17:31:38.468151Z"
    }
   },
   "cell_type": "code",
   "source": "test_df.info()",
   "id": "35c969b3ddc43ad7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25404 entries, 30793 to 89891\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   step            25404 non-null  int64  \n",
      " 1   type            25404 non-null  int64  \n",
      " 2   amount          25404 non-null  float64\n",
      " 3   nameOrig        25404 non-null  object \n",
      " 4   oldbalanceOrg   25404 non-null  float64\n",
      " 5   newbalanceOrig  25404 non-null  float64\n",
      " 6   nameDest        25404 non-null  object \n",
      " 7   oldbalanceDest  25404 non-null  float64\n",
      " 8   newbalanceDest  25404 non-null  float64\n",
      " 9   isFraud         25404 non-null  int64  \n",
      " 10  isFlaggedFraud  25404 non-null  int64  \n",
      "dtypes: float64(5), int64(4), object(2)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T17:31:39.116140Z",
     "start_time": "2025-07-17T17:31:39.105509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Collecting required features\n",
    "feature_columns = ['step', 'type','amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "\n",
    "target = 'isFraud'\n",
    "\n",
    "X_train = train_df[feature_columns].values\n",
    "y_train = train_df[target].values\n",
    "\n",
    "#\n",
    "# le = pre.LabelEncoder()\n",
    "# train_df['attack_cat_encoded'] = le.fit_transform(train_df['attack_cat'])\n",
    "\n",
    "X_test = test_df[feature_columns].values\n",
    "y_test = test_df[target].values"
   ],
   "id": "d879d96c98190a1f",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T17:31:39.842676Z",
     "start_time": "2025-07-17T17:31:39.811601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "original_train_rows = len(train_df)\n",
    "train_df = train_df[~((train_df['oldbalanceOrg'] == 0) & (train_df['newbalanceOrig'] == 0))]\n",
    "train_df = train_df[~((train_df['oldbalanceDest'] == 0) & (train_df['oldbalanceDest'] == 0))]\n",
    "filtered_train_rows = len(train_df)\n",
    "print(f\"Train_df: Filtered {original_train_rows - filtered_train_rows} rows where oldbalanceOrg and newbalanceOrig were both 0.\")\n",
    "print(f\"Remaining train_df rows: {filtered_train_rows}\")\n",
    "\n",
    "original_test_rows = len(test_df)\n",
    "test_df = test_df[~((test_df['oldbalanceOrg'] == 0) & (test_df['newbalanceOrig'] == 0))]\n",
    "test_df = test_df[~((test_df['oldbalanceDest'] == 0) & (test_df['newbalanceDest'] == 0))]\n",
    "filtered_test_rows = len(test_df)\n",
    "print(f\"Test_df: Filtered {original_test_rows - filtered_test_rows} rows where oldbalanceOrg and newbalanceOrig were both 0.\")\n",
    "print(f\"Remaining test_df rows: {filtered_test_rows}\")\n"
   ],
   "id": "8e8a7f63e5bffd1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_df: Filtered 49714 rows where oldbalanceOrg and newbalanceOrig were both 0.\n",
      "Remaining train_df rows: 26495\n",
      "Test_df: Filtered 15533 rows where oldbalanceOrg and newbalanceOrig were both 0.\n",
      "Remaining test_df rows: 9871\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T17:31:40.918854Z",
     "start_time": "2025-07-17T17:31:40.890275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Converting to tensor\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Converting to tensor and moving to the selected device\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)"
   ],
   "id": "81120687472a7ab",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T17:31:42.019627Z",
     "start_time": "2025-07-17T17:31:42.011273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 64\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"Data loaded from CSV and prepared for PyTorch.\")\n",
    "print(\"Training data shape:\", X_train_tensor.shape)\n",
    "print(\"Test data shape:\", X_test_tensor.shape)\n",
    "print(f\"Number of unique labels (classes): {len(np.unique(y_train))}\")\n"
   ],
   "id": "6f4f459bdb0bd14b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from CSV and prepared for PyTorch.\n",
      "Training data shape: torch.Size([76209, 1, 7])\n",
      "Test data shape: torch.Size([25404, 1, 7])\n",
      "Number of unique labels (classes): 2\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T17:31:43.023990Z",
     "start_time": "2025-07-17T17:31:43.012714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Net1DCNN(nn.Module):\n",
    "    def __init__(self, input_channels, sequence_length, num_classes):\n",
    "        super(Net1DCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "\n",
    "        # self.fc1 = nn.Linear(160 * 1, 64)\n",
    "        # self.fc2 = nn.Linear(64, num_classes)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.randn(1, input_channels, sequence_length)\n",
    "            dummy_output = self.pool1(self.relu1(self.conv1(dummy_input)))\n",
    "            dummy_output = self.pool2(self.relu2(self.conv2(dummy_output)))\n",
    "            flattened_size = dummy_output.view(dummy_output.size(0), -1).shape[1]\n",
    "\n",
    "        self.fc1 = nn.Linear(flattened_size, 128)\n",
    "        self.relu_fc = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "        # self.dropout1 = nn.Dropout(p=0.2)\n",
    "        # self.dropout2 = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # x = self.dropout1(x)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu_fc(x)\n",
    "        # x = self.dropout2(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ],
   "id": "6170ce8e879f03f9",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T17:34:21.276964Z",
     "start_time": "2025-07-17T17:33:12.742938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_channels = X_train_tensor.shape[1]\n",
    "sequence_length = X_train_tensor.shape[2]\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "model = Net1DCNN(input_channels=input_channels, sequence_length=sequence_length, num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Optimizers\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.05, momentum=0.5)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "print(\"\\nStarting model training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_accuracy = 100 * correct / total\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "print(\"Training finished.\")"
   ],
   "id": "33716de3afbcb857",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting model training...\n",
      "Epoch [1/10], Loss: 0.0129, Train Accuracy: 99.86%\n",
      "Epoch [2/10], Loss: 0.0074, Train Accuracy: 99.86%\n",
      "Epoch [3/10], Loss: 0.0069, Train Accuracy: 99.86%\n",
      "Epoch [4/10], Loss: 0.0066, Train Accuracy: 99.87%\n",
      "Epoch [5/10], Loss: 0.0066, Train Accuracy: 99.87%\n",
      "Epoch [6/10], Loss: 0.0064, Train Accuracy: 99.86%\n",
      "Epoch [7/10], Loss: 0.0063, Train Accuracy: 99.86%\n",
      "Epoch [8/10], Loss: 0.0062, Train Accuracy: 99.87%\n",
      "Epoch [9/10], Loss: 0.0061, Train Accuracy: 99.87%\n",
      "Epoch [10/10], Loss: 0.0061, Train Accuracy: 99.87%\n",
      "Training finished.\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T17:34:37.800424Z",
     "start_time": "2025-07-17T17:34:36.417142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "test_accuracies = 100 * correct / len(test_loader)\n",
    "print(f\"\\nAccuracy on the test set: {accuracy:.2f}%\")"
   ],
   "id": "40a63e320bb1cf8a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on the test set: 99.87%\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T17:34:39.066443Z",
     "start_time": "2025-07-17T17:34:38.903694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_dir = 'models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "model_path = os.path.join(model_dir, '1d_cnn_model.pth')\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"\\nModel saved to {model_path}\")"
   ],
   "id": "e88c7bce866c6de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved to models\\1d_cnn_model.pth\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c2699cc0f05ca801"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
