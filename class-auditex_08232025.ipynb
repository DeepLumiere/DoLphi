{
 "cells": [
  {
   "cell_type": "code",
   "id": "b2d98f4e79af9ce6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T16:32:15.201868Z",
     "start_time": "2025-08-22T16:31:53.605915Z"
    }
   },
   "source": [
    "# !pip install torch transformers soundfile moviepy numpy pandas nltk\n",
    "!pip install torch transformers soundfile moviepy numpy pandas nltk faiss-cpu"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in r:\\apps\\miniconda3\\lib\\site-packages (2.7.1+cu128)\n",
      "Requirement already satisfied: transformers in r:\\apps\\miniconda3\\lib\\site-packages (4.53.0)\n",
      "Collecting soundfile\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "Collecting moviepy\n",
      "  Downloading moviepy-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: numpy in r:\\apps\\miniconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: pandas in r:\\apps\\miniconda3\\lib\\site-packages (2.2.3)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.12.0-cp313-cp313-win_amd64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: filelock in r:\\apps\\miniconda3\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in r:\\apps\\miniconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in r:\\apps\\miniconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in r:\\apps\\miniconda3\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in r:\\apps\\miniconda3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in r:\\apps\\miniconda3\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: setuptools in r:\\apps\\miniconda3\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in r:\\apps\\miniconda3\\lib\\site-packages (from transformers) (0.33.1)\n",
      "Requirement already satisfied: packaging>=20.0 in r:\\apps\\miniconda3\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in r:\\apps\\miniconda3\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in r:\\apps\\miniconda3\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in r:\\apps\\miniconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in r:\\apps\\miniconda3\\lib\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in r:\\apps\\miniconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in r:\\apps\\miniconda3\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: cffi>=1.0 in r:\\apps\\miniconda3\\lib\\site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: decorator<6.0,>=4.0.2 in r:\\apps\\miniconda3\\lib\\site-packages (from moviepy) (5.1.1)\n",
      "Collecting imageio<3.0,>=2.5 (from moviepy)\n",
      "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting imageio_ffmpeg>=0.2.0 (from moviepy)\n",
      "  Downloading imageio_ffmpeg-0.6.0-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting proglog<=1.0.0 (from moviepy)\n",
      "  Downloading proglog-0.1.12-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting python-dotenv>=0.10 (from moviepy)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: pillow<12.0,>=9.2.0 in r:\\apps\\miniconda3\\lib\\site-packages (from moviepy) (11.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in r:\\apps\\miniconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in r:\\apps\\miniconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in r:\\apps\\miniconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: joblib in r:\\apps\\miniconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: pycparser in r:\\apps\\miniconda3\\lib\\site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in r:\\apps\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in r:\\apps\\miniconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in r:\\apps\\miniconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in r:\\apps\\miniconda3\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in r:\\apps\\miniconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in r:\\apps\\miniconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in r:\\apps\\miniconda3\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in r:\\apps\\miniconda3\\lib\\site-packages (from requests->transformers) (2025.6.15)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 10.8 MB/s eta 0:00:00\n",
      "Downloading moviepy-2.2.1-py3-none-any.whl (129 kB)\n",
      "Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Downloading proglog-0.1.12-py3-none-any.whl (6.3 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 9.3 MB/s eta 0:00:00\n",
      "Downloading faiss_cpu-1.12.0-cp313-cp313-win_amd64.whl (18.2 MB)\n",
      "   ---------------------------------------- 0.0/18.2 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 4.7/18.2 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 9.2/18.2 MB 22.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 13.6/18.2 MB 22.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  18.1/18.2 MB 22.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.2/18.2 MB 17.6 MB/s eta 0:00:00\n",
      "Downloading imageio_ffmpeg-0.6.0-py3-none-win_amd64.whl (31.2 MB)\n",
      "   ---------------------------------------- 0.0/31.2 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 4.7/31.2 MB 23.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 9.2/31.2 MB 22.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 13.9/31.2 MB 22.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 18.4/31.2 MB 22.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 22.3/31.2 MB 21.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 25.7/31.2 MB 20.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 27.8/31.2 MB 19.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 29.6/31.2 MB 18.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  31.2/31.2 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 31.2/31.2 MB 15.6 MB/s eta 0:00:00\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Installing collected packages: python-dotenv, imageio_ffmpeg, imageio, faiss-cpu, click, soundfile, proglog, nltk, moviepy\n",
      "\n",
      "   ---------------------------------------- 0/9 [python-dotenv]\n",
      "   ---- ----------------------------------- 1/9 [imageio_ffmpeg]\n",
      "   ---- ----------------------------------- 1/9 [imageio_ffmpeg]\n",
      "   ---- ----------------------------------- 1/9 [imageio_ffmpeg]\n",
      "   -------- ------------------------------- 2/9 [imageio]\n",
      "   -------- ------------------------------- 2/9 [imageio]\n",
      "   -------- ------------------------------- 2/9 [imageio]\n",
      "   -------- ------------------------------- 2/9 [imageio]\n",
      "   -------- ------------------------------- 2/9 [imageio]\n",
      "   -------- ------------------------------- 2/9 [imageio]\n",
      "   ------------- -------------------------- 3/9 [faiss-cpu]\n",
      "   ------------- -------------------------- 3/9 [faiss-cpu]\n",
      "   ------------- -------------------------- 3/9 [faiss-cpu]\n",
      "   ------------- -------------------------- 3/9 [faiss-cpu]\n",
      "   ------------- -------------------------- 3/9 [faiss-cpu]\n",
      "   ----------------- ---------------------- 4/9 [click]\n",
      "   ----------------- ---------------------- 4/9 [click]\n",
      "   -------------------------- ------------- 6/9 [proglog]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ------------------------------- -------- 7/9 [nltk]\n",
      "   ----------------------------------- ---- 8/9 [moviepy]\n",
      "   ----------------------------------- ---- 8/9 [moviepy]\n",
      "   ----------------------------------- ---- 8/9 [moviepy]\n",
      "   ----------------------------------- ---- 8/9 [moviepy]\n",
      "   ----------------------------------- ---- 8/9 [moviepy]\n",
      "   ---------------------------------------- 9/9 [moviepy]\n",
      "\n",
      "Successfully installed click-8.2.1 faiss-cpu-1.12.0 imageio-2.37.0 imageio_ffmpeg-0.6.0 moviepy-2.2.1 nltk-3.9.1 proglog-0.1.12 python-dotenv-1.1.1 soundfile-0.13.1\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "834f6e3d243ddd2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T16:32:35.196641Z",
     "start_time": "2025-08-22T16:32:35.191652Z"
    }
   },
   "source": [
    "%env HUGGINGFACE_HUB_CACHE= models"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HUGGINGFACE_HUB_CACHE=models\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-23T12:07:34.729280Z",
     "start_time": "2025-08-23T12:07:34.724557Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from moviepy import VideoFileClip, AudioFileClip\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline, WhisperProcessor, \\\n",
    "    WhisperForConditionalGeneration\n",
    "# from nemo.collections.asr.models import ClusteringDiarizer\n",
    "import soundfile as sf\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import re\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "id": "98c54699f2de8a13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T16:20:09.838423Z",
     "start_time": "2025-08-22T16:20:09.826565Z"
    }
   },
   "source": [
    "def extract_audio(input_file, output_folder=\"extracted_audio\"):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    base_name = os.path.basename(input_file)\n",
    "    file_name, file_ext = os.path.splitext(base_name)\n",
    "\n",
    "    output_file_path = os.path.join(output_folder, f\"{file_name}.mp3\")\n",
    "\n",
    "    if file_ext.lower() == \".mp4\":\n",
    "        print(f\"Detected MP4 file. Extracting audio from '{input_file}'...\")\n",
    "        try:\n",
    "            video_clip = VideoFileClip(input_file)\n",
    "            audio_clip = video_clip.audio\n",
    "            audio_clip.write_audiofile(output_file_path)\n",
    "            audio_clip.close()\n",
    "            video_clip.close()\n",
    "            print(f\"Audio extracted successfully and saved to '{output_file_path}'\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during MP4 processing: {e}\")\n",
    "\n",
    "    elif file_ext.lower() == \".mp3\":\n",
    "        print(f\"Detected MP3 file. Copying '{input_file}'...\")\n",
    "        try:\n",
    "            with open(input_file, 'rb') as f_in, open(output_file_path, 'wb') as f_out:\n",
    "                f_out.write(f_in.read())\n",
    "            print(f\"File copied successfully to '{output_file_path}'\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during MP3 processing: {e}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Unsupported file format: {file_ext}. Please provide an MP4 or MP3 file.\")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de04f51224bf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_audio(r\"C:\\Users\\dudec\\OneDrive\\Studies\\Coursera\\Google_AI_Essentials\\AI and future of work.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bd2a7669b099df",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_audio(r\"C:\\Users\\dudec\\OneDrive\\Studies\\Coursera\\Google_AI_Essentials\\AI and future of work.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2175ee89e3966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipe = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-large-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "ab29c8c2bc82cd70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T11:40:13.327310Z",
     "start_time": "2025-08-23T11:39:21.145303Z"
    }
   },
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float32 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\", torch_dtype=torch_dtype).to(device)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    "    # chunk_length_s=30,\n",
    "    # stride_length_s=(4, 2),\n",
    "    generate_kwargs={\"language\": \"en\", \"task\": \"transcribe\"}\n",
    ")\n",
    "\n",
    "audio_file_path = r\"extracted_audio\\lR-ip0EZQXS_uczWPpahSQ_b9e17546063c4d59822e7488419afbf1_200826.005_MP4_720.mp3\"\n",
    "\n",
    "data, samplerate = sf.read(audio_file_path)\n",
    "\n",
    "if len(data.shape) > 1:\n",
    "    mono_data = np.mean(data, axis=1)\n",
    "else:\n",
    "    mono_data = data\n",
    "\n",
    "result = pipe({\"array\": mono_data, \"sampling_rate\": samplerate}, return_timestamps=True)\n",
    "\n",
    "print(result[\"text\"])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cuda\n",
      "R:\\Apps\\miniconda3\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:604: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Welcome to this video on the Flutter development environment. After watching this video you'll be able to describe the main components of Flutter development, identify the Dart programming language, identify emulators and physical devices, explain how the main components of Flutter work together. Flutter is an open-source user interface or UI software development toolkit. Developers use it to develop cross-platform applications by just writing code once. Flutter helps developers create native applications for iOS, Android, and the web with consistent UI. What makes this work is Flutter's main components. These include Flutter software development kit or SDK, the Dart programming language, Integrated Development Environment, or IDE, and emulators and physical devices. Let's explore those main components in more detail. The Flutter SDK is a collection of tools that developers need to create applications with Flutter. It includes the Dart SDK, which is essential for running and compiling Flutter apps. The SDK provides developers with everything required to build, test, and deploy Flutter applications. It includes libraries, tools for compiling code into native machine code, and tools for debugging. Flutter applications are written in Dart, an open-source programming language. Dart is optimized for UI development, making it an ideal choice for building fast and responsive apps. Dart's syntax is easy to learn for developers familiar with other programming languages such as JavaScript or Java. Dart also supports ahead-of-time AOT compilation, where Dart code is compiled into native machine code before the application is run for faster startup times. It also supports just-in-time JIT compilation, where Dart code is compiled into intermediate code, which is then interpreted and compiled into machine code at runtime. By supporting both AOT and JIT compilation, Dart provides the performance needed for production applications and the flexibility required for rapid development. Another main component of Flutter is the availability of IDEs, which offer features such as code completion, debugging, and emulation to streamline the development process. Popular IDEs for Flutter development include Visual Studio Code, IntelliJ IDEA, and Android Studio. Visual Studio Code is popular for its lightweight nature and extensive plug-in ecosystem, while IntelliJ IDEA and Android Studio have more integrated tools and features for development. Flutter also supports both emulators and physical devices to help developers test applications. Developers can run and test Flutter apps on emulators, which are virtual devices that mimic various real-world devices and configurations. While emulators simulate mobile devices on a computer, testing on physical devices provides real-world testing environments. Emulators are great for quickly testing apps across different devices and screen sizes. on physical devices helps developers examine the performance and user experience of the app on an actual device. Now let's examine building apps in Flutter to understand how these components work together. For example, imagine you're creating a to-do list application using Flutter. You create a new Flutter project using the Flutter SDK. This project includes the necessary files and folders to get started. The Flutter SDK provides a command line tool which is used to create new projects, run the app and more. After setting up your project, you start using Dart to write the core logic of your to-do list app. This step includes managing tasks, adding new tasks, and marking tasks as completed. Next, you manage the state of your app using Flutter's built-in state management techniques. For state management, you use Stateful Widget to manage dynamic changes, such as adding or completing tasks. Effective state management ensures that your app responds quickly and correctly to user inputs and changes in data. After you've built your app in Flutter, you test your to-do list app on emulators and physical devices to ensure the app works smoothly across different environments. You use the debugging tools provided by your IDE to troubleshoot any issues. When testing and debugging are completed, you are ready to share your app with users. The Flutter Development Environment combines powerful tools and a robust programming language to help you build high-quality cross-platform applications. By understanding these key components and how they integrate, you can effectively develop and deploy Flutter apps. In this video, you learned that. The main components of Flutter development include the Flutter software development kit, SDK, the Dart programming language, integrated development environments, IDEs, and emulators and physical devices. Flutter applications are written in Dart, an open source programming language that is optimized for user interface UI development. Flutter uses emulators and physical devices to test the performance and user experience of apps on different devices. The main steps of building an app in Flutter include project setup, using Dart for logic, managing states in the app and testing the app on emulators and physical devices.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "73453bf4c2f4aecd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T11:40:51.171019Z",
     "start_time": "2025-08-23T11:40:50.833838Z"
    }
   },
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    words = text.lower().split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, pos='v') for word in words]\n",
    "    return \" \".join(lemmatized_words)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "e4edd538f2820d96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T11:40:55.799828Z",
     "start_time": "2025-08-23T11:40:52.626411Z"
    }
   },
   "source": "processed_text = lemmatize_text(result[\"text\"])",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "4057b5f79a3ecc97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T11:40:56.713326Z",
     "start_time": "2025-08-23T11:40:56.704539Z"
    }
   },
   "source": [
    "processed_text"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"welcome to this video on the flutter development environment. after watch this video you'll be able to describe the main components of flutter development, identify the dart program language, identify emulators and physical devices, explain how the main components of flutter work together. flutter be an open-source user interface or ui software development toolkit. developers use it to develop cross-platform applications by just write code once. flutter help developers create native applications for ios, android, and the web with consistent ui. what make this work be flutter's main components. these include flutter software development kit or sdk, the dart program language, integrate development environment, or ide, and emulators and physical devices. let's explore those main components in more detail. the flutter sdk be a collection of tool that developers need to create applications with flutter. it include the dart sdk, which be essential for run and compile flutter apps. the sdk provide developers with everything require to build, test, and deploy flutter applications. it include libraries, tool for compile code into native machine code, and tool for debugging. flutter applications be write in dart, an open-source program language. dart be optimize for ui development, make it an ideal choice for build fast and responsive apps. dart's syntax be easy to learn for developers familiar with other program languages such as javascript or java. dart also support ahead-of-time aot compilation, where dart code be compile into native machine code before the application be run for faster startup times. it also support just-in-time jit compilation, where dart code be compile into intermediate code, which be then interpret and compile into machine code at runtime. by support both aot and jit compilation, dart provide the performance need for production applications and the flexibility require for rapid development. another main component of flutter be the availability of ides, which offer feature such as code completion, debugging, and emulation to streamline the development process. popular ides for flutter development include visual studio code, intellij idea, and android studio. visual studio code be popular for its lightweight nature and extensive plug-in ecosystem, while intellij idea and android studio have more integrate tool and feature for development. flutter also support both emulators and physical devices to help developers test applications. developers can run and test flutter apps on emulators, which be virtual devices that mimic various real-world devices and configurations. while emulators simulate mobile devices on a computer, test on physical devices provide real-world test environments. emulators be great for quickly test apps across different devices and screen sizes. on physical devices help developers examine the performance and user experience of the app on an actual device. now let's examine build apps in flutter to understand how these components work together. for example, imagine you're create a to-do list application use flutter. you create a new flutter project use the flutter sdk. this project include the necessary file and folders to get started. the flutter sdk provide a command line tool which be use to create new projects, run the app and more. after set up your project, you start use dart to write the core logic of your to-do list app. this step include manage tasks, add new tasks, and mark task as completed. next, you manage the state of your app use flutter's built-in state management techniques. for state management, you use stateful widget to manage dynamic changes, such as add or complete tasks. effective state management ensure that your app respond quickly and correctly to user input and change in data. after you've build your app in flutter, you test your to-do list app on emulators and physical devices to ensure the app work smoothly across different environments. you use the debug tool provide by your ide to troubleshoot any issues. when test and debug be completed, you be ready to share your app with users. the flutter development environment combine powerful tool and a robust program language to help you build high-quality cross-platform applications. by understand these key components and how they integrate, you can effectively develop and deploy flutter apps. in this video, you learn that. the main components of flutter development include the flutter software development kit, sdk, the dart program language, integrate development environments, ides, and emulators and physical devices. flutter applications be write in dart, an open source program language that be optimize for user interface ui development. flutter use emulators and physical devices to test the performance and user experience of apps on different devices. the main step of build an app in flutter include project setup, use dart for logic, manage state in the app and test the app on emulators and physical devices.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "97772a9923dae58b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T12:09:31.733139Z",
     "start_time": "2025-08-23T12:09:26.473753Z"
    }
   },
   "source": [
    "# This is an example of what would need to be added\n",
    "\n",
    "# Load a pre-trained sentence-transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "base_sentences = [s.strip() for s in re.split(r'[.?!]\\s+', processed_text) if s.strip()]\n",
    "test_sentences = base_sentences[:]\n",
    "# Get embeddings for your processed texts\n",
    "base_embeddings = model.encode(base_sentences)\n",
    "test_embeddings = model.encode(test_sentences)"
   ],
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T12:12:58.935370Z",
     "start_time": "2025-08-23T12:12:57.125312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "range_n_clusters = list(range(5, 15))\n",
    "silhouette_scores = []\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    clustering_model = KMeans(n_clusters=n_clusters, random_state=0, n_init=15)\n",
    "    cluster_labels = clustering_model.fit_predict(base_embeddings)\n",
    "\n",
    "    score = silhouette_score(base_embeddings, cluster_labels)\n",
    "    silhouette_scores.append(score)\n",
    "    print(f\"Number of clusters: {n_clusters}, Silhouette Score: {score:.4f}\")\n",
    "\n",
    "optimal_n_clusters = range_n_clusters[np.argmax(silhouette_scores)]"
   ],
   "id": "71cf4eedbbb3e2e4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R:\\Apps\\miniconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "R:\\Apps\\miniconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 5, Silhouette Score: 0.1291\n",
      "Number of clusters: 6, Silhouette Score: 0.1040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R:\\Apps\\miniconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "R:\\Apps\\miniconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 7, Silhouette Score: 0.1238\n",
      "Number of clusters: 8, Silhouette Score: 0.1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R:\\Apps\\miniconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "R:\\Apps\\miniconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 9, Silhouette Score: 0.0724\n",
      "Number of clusters: 10, Silhouette Score: 0.1025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R:\\Apps\\miniconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "R:\\Apps\\miniconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 11, Silhouette Score: 0.0971\n",
      "Number of clusters: 12, Silhouette Score: 0.1129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R:\\Apps\\miniconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 13, Silhouette Score: 0.1079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R:\\Apps\\miniconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 14, Silhouette Score: 0.1095\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T12:13:00.757661Z",
     "start_time": "2025-08-23T12:13:00.629364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_clustering_model = KMeans(n_clusters=optimal_n_clusters, random_state=0, n_init=10)\n",
    "final_cluster_labels = final_clustering_model.fit_predict(base_embeddings)"
   ],
   "id": "b17647cb5b110202",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R:\\Apps\\miniconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T12:13:02.977394Z",
     "start_time": "2025-08-23T12:13:02.969884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "merged_sentences = []\n",
    "merged_embeddings = []\n",
    "for i in range(optimal_n_clusters):\n",
    "    cluster_indices = np.argwhere(final_cluster_labels == i).flatten()\n",
    "\n",
    "    if len(cluster_indices) > 0:\n",
    "        cluster_sentences = [base_sentences[j] for j in cluster_indices]\n",
    "        cluster_embeddings = base_embeddings[cluster_indices]\n",
    "\n",
    "        cluster_centroid = np.mean(cluster_embeddings, axis=0)\n",
    "        distances = np.linalg.norm(cluster_embeddings - cluster_centroid, axis=1)\n",
    "        closest_sentence_idx = np.argmin(distances)\n",
    "\n",
    "        representative_sentence = cluster_sentences[closest_sentence_idx]\n",
    "        merged_sentences.append(representative_sentence)\n",
    "        merged_embeddings.append(cluster_centroid)\n"
   ],
   "id": "14d309370c81fc38",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T12:13:04.091573Z",
     "start_time": "2025-08-23T12:13:04.082429Z"
    }
   },
   "cell_type": "code",
   "source": "merged_sentences",
   "id": "e750c6f20075ad3e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"next, you manage the state of your app use flutter's built-in state management techniques\",\n",
       " 'it also support just-in-time jit compilation, where dart code be compile into intermediate code, which be then interpret and compile into machine code at runtime',\n",
       " 'the flutter sdk be a collection of tool that developers need to create applications with flutter',\n",
       " 'it include libraries, tool for compile code into native machine code, and tool for debugging',\n",
       " 'flutter use emulators and physical devices to test the performance and user experience of apps on different devices']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "id": "dc56692f80369c32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T12:13:05.351031Z",
     "start_time": "2025-08-23T12:13:05.346318Z"
    }
   },
   "source": [
    "merged_embeddings = np.array(merged_embeddings)\n",
    "vector_dimension = merged_embeddings.shape[1]"
   ],
   "outputs": [],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "id": "afac6eed1fe7cb39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T12:13:22.782389Z",
     "start_time": "2025-08-23T12:13:22.777899Z"
    }
   },
   "source": [
    "faiss_index = faiss.IndexFlatIP(vector_dimension)\n",
    "faiss_index.add(test_embeddings)\n",
    "\n",
    "# distances, _ = faiss_index.search(base_embeddings, k=1)\n",
    "distances, _ = faiss_index.search(merged_embeddings, k=1)\n",
    "\n",
    "similarity_scores = distances.flatten()"
   ],
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T12:13:23.485171Z",
     "start_time": "2025-08-23T12:13:23.480315Z"
    }
   },
   "cell_type": "code",
   "source": "similarity_scores",
   "id": "9091d4fd92dc9e04",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63831323, 0.80729413, 0.7520376 , 0.4428746 , 0.7568732 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7100c025daf820",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer(stop_words='english')\n",
    "# vectorizer = TfidfVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8e500e15e8043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform([processed_text])\n",
    "features = vectorizer.get_feature_names_out()\n",
    "# print(\"Features (words) kept:\", vectorizer.get_feature_names_out())\n",
    "word_counts = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903f788d438e7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = [word for word in processed_text.split() if word in features]\n",
    "paragraph_with_features = \" \".join(filtered_words)\n",
    "filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d119719cfbd670ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=word_counts, columns=features)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3f0b14d5a28370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
